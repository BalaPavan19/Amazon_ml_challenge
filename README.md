# Amazon_ml_challenge
Res Net 50 - Convert to embeddings       
Light GBM - Regression predictions
Amazon S3 Buckets
Pandas - Read Data   
Tensorflow
Optimized the dataset by reducing the size from 2 lakh to 20,755 images, ensuring better manageability without compromising data diversity.

Transitioned to Amazon SageMaker for better resource allocation and scalability to train the model efficiently.

Leveraged S3 buckets for image storage and retrieval, streamlining the data pipeline for training.

Implemented LightGBM for faster and more efficient model training, focusing on the project goal of obtaining high F1 scores for predictions.
